{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from compute_magazines.load_datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "htrc_records = pd.read_csv(\"../datasets/original_files/htrc_third_world_records.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "htrc_records.Record_URL = htrc_records.Record_URL.str.replace(\n",
    "    ';', ',').str.split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_htrc_records = htrc_records.explode('Record_URL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['La Documentation Arabe ', 'Afrique Documents', 'OAU Bulletin',\n",
       "       'IM information bulletin /Mozambique Information Agency',\n",
       "       'News from Xinhua News Agency, China.Daily bulletin',\n",
       "       \"Bulletin d’information  Bureau d'information du Gouvernement révolutionnaire provisoire de la République du Sud Viet-Nam à Paris.\",\n",
       "       'Révolution africaine', 'Arab Observer and The Scribe',\n",
       "       'Afro Asian Bulletin', 'al-Nashrah al-Ifrīqīyah al-Āsyawīyah',\n",
       "       'Afro Asian Peoples', 'Afro Asian and World Affairs',\n",
       "       'Solidarity AAPSO', 'Tricontinental', 'Afro Asian Women',\n",
       "       'Solidarity SWAPO', 'Asia and Africa today', 'Spearhead',\n",
       "       'Mozambican Revolution', 'Black News', 'Black World',\n",
       "       'Negro Digest', 'Direct from Cuba', 'Lotus',\n",
       "       'Nahdat Ifriqiyah/African Renaissance', 'Liberator', 'Freedomways',\n",
       "       'LSM news /Liberation Support Movement, Information Center',\n",
       "       'Presence Africaine'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_htrc_records.Periodical_Name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = cleaned_htrc_records.Record_URL[0]\n",
    "# result = requests.get(url)\n",
    "# ht_page = result.content\n",
    "# soup = BeautifulSoup(ht_page, 'html.parser')\n",
    "\n",
    "# rows = soup.find_all('tr')\n",
    "# for row in rows:\n",
    "\n",
    "#     if row.find(class_=\"IndItem\"):\n",
    "#         print('links', row.find('a').get('href'))\n",
    "#         print('dates', row.find(class_=\"IndItem\").text)\n",
    "#         print(row.find_all('td')[-1].get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../datasets/original_files/htrc_third_world_records_links_with_metadata.csv\"):\n",
    "    links_df = pd.read_csv(\"../datasets/original_files/htrc_third_world_records_links_with_metadata.csv\")\n",
    "else:\n",
    "    dfs = []\n",
    "    progress_bar = tqdm(total=len(cleaned_htrc_records), desc=\"Getting HathiTrust links\")\n",
    "    for index, row in cleaned_htrc_records.iterrows():\n",
    "        progress_bar.update(1)\n",
    "        url = row['Record_URL']\n",
    "        result = requests.get(url)\n",
    "        ht_page = result.content\n",
    "        soup = BeautifulSoup(ht_page, 'html.parser')\n",
    "\n",
    "        table_rows = soup.find_all('tr')\n",
    "\n",
    "        for table_row in table_rows:\n",
    "            if table_row.find('a', class_=\"rights-Array searchonly\"):\n",
    "                link = table_row.find('a', class_=\"rights-Array searchonly\").get('href')\n",
    "                htid = link.split('/')[-1]\n",
    "                date = table_row.find(class_=\"IndItem\").text\n",
    "                source = table_row.find_all('td')[-1].get_text()\n",
    "                new_df = {}\n",
    "                new_df['link'] = link\n",
    "                new_df['htid'] = htid\n",
    "                new_df['date'] = date\n",
    "                new_df['original_source'] = source\n",
    "                new_df['record_url'] = url\n",
    "                new_df['periodical_name'] = row['Periodical_Name']\n",
    "                new_df['publication_type'] = row['Type']\n",
    "                dfs.append(new_df)\n",
    "    progress_bar.close()\n",
    "    links_df = pd.DataFrame(dfs)\n",
    "    links_df.to_csv(\"../original_files/htrc_third_world_records_links.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../datasets/ht_ef_datasets/full_hathitrust_annotated_magazines_with_htids.csv'\n",
    "output_directory = \"../datasets/ht_ef_datasets/\"\n",
    "df = get_full_combined_dataset(output_path, output_directory)\n",
    "output_path = \"../datasets/ht_ef_datasets/combined_full_hathitrust_annotated_magazines_with_htids.csv\"\n",
    "issues_df = get_combined_issues(output_path, df)\n",
    "if os.path.exists(\"../datasets/original_files/htrc_third_world_records_links_with_metadata.csv\"):\n",
    "    full_links_df = pd.read_csv(\"../datasets/original_files/htrc_third_world_records_links_with_metadata.csv\")\n",
    "else:\n",
    "    htrc_periodicals_full = pd.read_csv(\"../datasets/original_files/htrc_periodicals_se.csv\")\n",
    "    full_links_df = pd.merge(links_df, htrc_periodicals_full, on='htid', how='left')\n",
    "    full_links_df.to_csv(\"../datasets/original_files/htrc_third_world_records_links_with_metadata.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['afro-asian_and_world_affairs', 'afro-asian_bulletin_',\n",
       "       'afro-asian_peoples', 'arab_observer',\n",
       "       'arab_observer_and_the_scribe', 'liberator', 'lotus', 'solidarity',\n",
       "       'the_scribe', 'tricontinental'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_df.cleaned_magazine_title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_df.start_issue.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from htrc_features import FeatureReader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inu.30000093395964'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htid = full_links_df.htid[0]\n",
    "htid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_links_df = links_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_links_df[\"keep_periodical\"] = True\n",
    "list_of_existing_periodicals = [\n",
    "    \"Afro Asian and World Affairs\", \"Afro Asian Bulletin\", \"Afro Asian Peoples\", \"Arab Observer and The Scribe\", \"Freedomways\", \"Liberator\", \"Lotus\", \"Solidarity AAPSO\", \"Tricontinental\"]\n",
    "full_links_df.loc[full_links_df.periodical_name.isin(list_of_existing_periodicals), \"keep_periodical\"] = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodicals = full_links_df[full_links_df.keep_periodical == True].periodical_name.unique().tolist()\n",
    "\n",
    "periodicals = [periodical.strip().replace(\" \", \"_\").replace('.', '').replace('/', '') for periodical in periodicals]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_links_df['directory_name'] = \"../ht_ef_datasets/\" +full_links_df.periodical_name.str.strip().str.replace(\" \", \"_\").str.replace('.', '').str.replace('/', '') + \"_HathiTrust/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# for periodical in periodicals:\n",
    "#     os.mkdir(f\"../ht_ef_datasets/{periodical}_HathiTrust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_links_df['directory_exists'] = full_links_df.directory_name.apply(lambda x: os.path.exists(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_links_df.to_csv(\"../original_files/htrc_third_world_records_links_with_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting HathiTrust volumes:   0%|          | 0/353 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m             row_df \u001b[39m=\u001b[39m row_df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmetadata_title\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpub_place\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmetadata_pub_place\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmetadata_author\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpub_date\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmetadata_pub_date\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmetadata_language\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgenre\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmetadata_genre\u001b[39m\u001b[39m'\u001b[39m,})\n\u001b[1;32m     12\u001b[0m             cols \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(vol_df\u001b[39m.\u001b[39mcolumns)\u001b[39m&\u001b[39m \u001b[39mset\u001b[39m(row_df\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m---> 13\u001b[0m             merged_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(vol_df, row_df, on\u001b[39m=\u001b[39;49mcols, how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m             dfs\u001b[39m.\u001b[39mappend(merged_df)\n\u001b[1;32m     16\u001b[0m progress_bar\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:124\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m    110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:775\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[1;32m    773\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 775\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[1;32m    776\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[1;32m    777\u001b[0m )\n\u001b[1;32m    778\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:766\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    764\u001b[0m left\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m llabels\n\u001b[1;32m    765\u001b[0m right\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m rlabels\n\u001b[0;32m--> 766\u001b[0m result \u001b[39m=\u001b[39m concat([left, right], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    767\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/reshape/concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[1;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/internals/concat.py:233\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    231\u001b[0m     fastpath \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m values\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    232\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 233\u001b[0m     values \u001b[39m=\u001b[39m _concatenate_join_units(join_units, concat_axis, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    234\u001b[0m     fastpath \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m fastpath:\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/internals/concat.py:542\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m    539\u001b[0m has_none_blocks \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units)\n\u001b[1;32m    540\u001b[0m upcasted_na \u001b[39m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[0;32m--> 542\u001b[0m to_concat \u001b[39m=\u001b[39m [\n\u001b[1;32m    543\u001b[0m     ju\u001b[39m.\u001b[39mget_reindexed_values(empty_dtype\u001b[39m=\u001b[39mempty_dtype, upcasted_na\u001b[39m=\u001b[39mupcasted_na)\n\u001b[1;32m    544\u001b[0m     \u001b[39mfor\u001b[39;00m ju \u001b[39min\u001b[39;00m join_units\n\u001b[1;32m    545\u001b[0m ]\n\u001b[1;32m    547\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(to_concat) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    548\u001b[0m     \u001b[39m# Only one block, nothing to concatenate.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     concat_values \u001b[39m=\u001b[39m to_concat[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/internals/concat.py:543\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    539\u001b[0m has_none_blocks \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units)\n\u001b[1;32m    540\u001b[0m upcasted_na \u001b[39m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[1;32m    542\u001b[0m to_concat \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 543\u001b[0m     ju\u001b[39m.\u001b[39;49mget_reindexed_values(empty_dtype\u001b[39m=\u001b[39;49mempty_dtype, upcasted_na\u001b[39m=\u001b[39;49mupcasted_na)\n\u001b[1;32m    544\u001b[0m     \u001b[39mfor\u001b[39;00m ju \u001b[39min\u001b[39;00m join_units\n\u001b[1;32m    545\u001b[0m ]\n\u001b[1;32m    547\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(to_concat) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    548\u001b[0m     \u001b[39m# Only one block, nothing to concatenate.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     concat_values \u001b[39m=\u001b[39m to_concat[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/internals/concat.py:522\u001b[0m, in \u001b[0;36mJoinUnit.get_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    521\u001b[0m     \u001b[39mfor\u001b[39;00m ax, indexer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindexers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 522\u001b[0m         values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(values, indexer, axis\u001b[39m=\u001b[39;49max)\n\u001b[1;32m    524\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[0;32m~/.virtualenvs/htrc-periodicals-venv/lib/python3.9/site-packages/pandas/core/array_algos/take.py:158\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    156\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(out_shape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    160\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    161\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[1;32m    162\u001b[0m )\n\u001b[1;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "progress_bar = tqdm(total=len(full_links_df[full_links_df.keep_periodical == True]), desc=\"Getting HathiTrust volumes\")\n",
    "for _, row in full_links_df[full_links_df.keep_periodical == True].iterrows():\n",
    "    progress_bar.update(1)\n",
    "    dir_name = row['directory_name']\n",
    "    for dir, subdir, files in os.walk(dir_name):\n",
    "        for file in files:\n",
    "            vol_df = pd.read_csv(dir_name + file)\n",
    "            \n",
    "            row_df = pd.DataFrame(row).T\n",
    "            row_df = row_df.rename(columns={'title': 'metadata_title', 'pub_place': 'metadata_pub_place', 'author': 'metadata_author', 'pub_date': 'metadata_pub_date', 'language': 'metadata_language', 'genre': 'metadata_genre',})\n",
    "            cols = list(set(vol_df.columns)& set(row_df.columns))\n",
    "            merged_df = pd.merge(vol_df, row_df, on=cols, how='left')\n",
    "            dfs.append(merged_df)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sequence', 'section', 'token', 'pos', 'count', 'htid', 'title',\n",
       "       'author', 'pub_date', 'pub_place', 'language', 'publisher', 'genre',\n",
       "       'source_institution', 'link', 'date', 'original_source', 'record_url',\n",
       "       'periodical_name', 'publication_type', 'access', 'rights', 'ht_bib_key',\n",
       "       'description', 'source', 'source_bib_num', 'oclc_num', 'isbn', 'issn',\n",
       "       'lccn', 'metadata_title', 'imprint', 'rights_reason_code',\n",
       "       'rights_timestamp', 'us_gov_doc_flag', 'rights_date_used',\n",
       "       'metadata_pub_place', 'lang', 'bib_fmt', 'collection_code',\n",
       "       'content_provider_code', 'responsible_entity_code',\n",
       "       'digitization_agent_code', 'access_profile_code', 'metadata_author',\n",
       "       'keep_periodical', 'directory_name', 'directory_exists'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_bar = tqdm(total=len(full_links_df[full_links_df.keep_periodical == True]), desc=\"Getting HathiTrust links\")\n",
    "# for index, row in full_links_df[full_links_df.keep_periodical == True].iterrows():\n",
    "#     progress_bar.update(1)\n",
    "#     dir_path = row.directory_name\n",
    "#     htid = row.htid\n",
    "#     file_name = row.periodical_name.replace(\" \", \"_\").replace(\n",
    "#         '.', '').replace('/', '') + '_' + htid.replace('.', '_')\n",
    "#     if os.path.exists(dir_path + file_name + '.csv'):\n",
    "#         continue\n",
    "#     try: \n",
    "#         vols = FeatureReader(ids=[htid])\n",
    "#         for vol in vols:\n",
    "            \n",
    "#             volume_df = vol.tokenlist(section='all')\n",
    "#             volume_df = volume_df.reset_index()\n",
    "#             volume_df = volume_df.rename(\n",
    "#                 columns={'lowercase': 'token', 'page': 'sequence'})\n",
    "#             volume_df['htid'] = htid\n",
    "#             volume_df['title'] = vol.title\n",
    "#             volume_df['author'] =','.join(vol.author)\n",
    "#             volume_df['pub_date'] = vol.pub_date\n",
    "#             volume_df['pub_place'] = vol.pub_place\n",
    "#             volume_df['language'] = vol.language\n",
    "#             volume_df['publisher'] = vol.publisher\n",
    "#             volume_df['genre'] = ','.join(vol.genre)\n",
    "#             volume_df['source_institution'] = vol.source_institution\n",
    "#             volume_df.to_csv(f\"{dir_path}{file_name}.csv\", index=False)\n",
    "#     except:\n",
    "#         print(f\"Error getting {htid} for {row.periodical_name}\")\n",
    "# progress_bar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htrc-periodicals-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c381cce0a11cdbd185210d50217a0d0995dd5a70dabd1dcfa7b80ed438c02b46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
